#Preamble: Laying out the plan for Project 3. Mohammad Wahidi, Yichen Yao
  We split this project in three main parts to make it easier for us to follow the work we were collaborating on and to make sure the implementations were correct. Like the phases in the project description, we had part 1 which related to the semaphore implementation and part two which dealth with the TPS library and finally part 3, the testing connected to the tps implementation. We took it one step at a time, frequently checking piazza as it was an extremely valuable resource as many of the questions we had, our peers had asked before us.
##Part 1 : Semaphore API
	Since semaphore is managing the resources used by multiple threads, so we need data from both resources and the threads.  We build the structure of semaphore containing an integer count of the number of available resources, and queue called waitingQ of predefined type queue_t which stores the threads requesting the resource. 
	sem_create is first called before any operations can be done on semaphore because we don’t have any semaphore before this function. It initializes a semaphore with a number of resource, specified by the argument, while allocating an empty queue for the future thread to enqueue. 
	sem_destory deallocates the specified semaphore simply by deallocating the queue within the semaphore, because the queue is also pre-allocated, freeing the queue first then we can also free the semaphore. 
	sem_down checks whether the sem is null or not, if the sem is null, return false because no further operations is necessary. Using pthread_self and assign the tid of calling thread with the newly created pthread_t type variable called new, and allocate the new with address pointer called new_addr. We have two cases where we have enough resource (count > 0) or we don’t have enough resource (count = 0). because we are taking the calling thread into the waitingQ (the queue of our semaphore) by calling queue_enqueue , enter_critical_section(); is called right after the assignment of the new thread to ensure mutual exclusion. In the first case, we simply decrement the number of resource (count) and exit the critical section. In the second case, we enqueue the calling thread and block it (thread_block) since the thread can’t have any resource. 
 	sem_up  unblocks the thread if exists in the waitingQ after dequeueing it, increment the number of available resource otherwise. 
	sem_getvalue( ) has two cases: resource available and resources not available. If the first case, returns the number of available resource, if we have the second case, we return the negative value of how many thread are blocked inside the our queue implement, which is the length of queue. 
  The semaphore api overall was simple on the surface, but the edge cases, specifically sem_up and sem_down as noted in the instructions, gave us trouble when debugging and running our code but after understanding what each one was causing, in regards to protection, we were able to flesh out the details and fix our segmentation faults.
  ##Part 2: TPS API
    After finishing the semaphore api, we moved onto the TPS portion. We realized this would be the bulk of the project, so we started immediately. Our first step was to set up the api correctly. Thanks to some piazza browsing as well as a more thorough reading of the instructions, we came to the understanding that the API impelmentation could be very similar to the queue implementation we made in project 2. 
    Our initial step was to initialize the global queue. Similar to the previous projects, the global variable allowed to us initialize, use and iterat through the queue without having to worry about memory scope issues, which gave us flexibility in our code. After that, we created structs for both the page and tps structs, as well as initiliazing their types for ease of use. 
    Once the base api was done, we moved onto our search functions. The first function, finding the tid, was repurposed from project two as it accomplished the same job with some minor tweaks. We decided on casting the arg to a pthread_t rather than initializing a variable and then allocating and casting it as it seemed cleaner the way we did it. Similarly, for the page search function, since we had the page address stored as a void pointer, allowed us to compare without casting or having to worry about pointer issues.
    Our first real function we started on was tps_init. After doing the segmentation and signal handler, our function checked for an existing queue, and if no error, started the queue, checked for errors again, and returned. Simple enough to do, and not much to go wrong on here.
    Next was tps_create and tps_destroy, which were fairly similar to each other. We allocated memory,entered the critical section grabbed the correct threads, and mapped them and set their protections using mmap. In tps_create, once checked for errors, we enqueue the tps block, exit the critical and return if all went according to plan. For tps_destroy, it was the opposite in a sense. We grab the thread from the queue, delete it from the queue if it exists, then check its reference count to make sure we have the correct object. If the count was not 1, we decremented and returned. If it was 1, we remove the mapping for the page address, free the memory and exit the critical section if no errors arose.
    In tps_read and tps_write, the implementations were similar, with some nuances, due to the nature of mprotect and memcpy. For tps_read, we grab the current tid, initialize a tps block, enter the critical section and iterate for the thread, checking for errors such as NULL thread and buffer, and out of bounds memory errors. Once started, we change the permissions on the thread to allow reading at the given page address, we copy its content over to buffer to the specified offset and length, and then switch protections back to PROT_NONE, then exiting the critical section and returning. For tps_write, the process was very similar, doing the same first steps as tps_read until the iteration. From there, we deviated and checked reference counts for page adresses. If the count was greater than 1, it was a new page, and thus we allocated the memory for it to the size of the struct page. Here we used mmap again, as we are dealing with pages, to map and set protections on the block. Using PROT_WRITE, we were now able to modify the thread. After updating the reference count, we then allowed both read and write using mprotect. We copy the old address and point it to the new one, and we reset protections on both the page and tps block before exiting. If the reference count was 1, we skip that entire block of code and update the protections, but skip the new page allocation and exit after.
    Finally the last of part 2, tps_clone. We initiliaze a few variables for easy tracking. Tid, our current thread we want to copy to and the thread we wish to copy. We check to make sure tempdata does not exist yet, then we initialize the tps block. We point the block to the current thread and move on to our target thread. We search for the target thread using the given paramater tid, and then once found, we copy the data over and increment the reference count so we know which thread is which. After the data is copied, we enqueue the cloned data, exit the critical section and return. And that was it for our tps implementation.
    ##Part 3: TPStester
    For our tester, we started with a fairly basic approach. Starting out with a few simple tests such as initiliazing twice to check for errors, creating multiple threads and reading/writing with varying lengths and strings. We started the clone and segmentation testing and implemented some helper functions similar to tps_simple that allowed to test edges such as sem_up and sem_down. Otherwise, the implementations were fairly straightforward, and if our testing "worked"(both errors and successes), printed out to the console which allowed us to check if they worked and if any were missing, easily identified and taken care of.
